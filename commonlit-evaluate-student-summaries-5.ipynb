{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86aad52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:10:18.888347Z",
     "iopub.status.busy": "2023-09-14T01:10:18.887923Z",
     "iopub.status.idle": "2023-09-14T01:10:47.847263Z",
     "shell.execute_reply": "2023-09-14T01:10:47.845693Z"
    },
    "papermill": {
     "duration": 28.972091,
     "end_time": "2023-09-14T01:10:47.849904",
     "exception": false,
     "start_time": "2023-09-14T01:10:18.877813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/bitsandbytes/bitsandbytes-0.41.1-py3-none-any.whl\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.41.1\r\n",
      "Processing /kaggle/input/peft-whl/peft-0.4.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (6.0)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (2.0.0)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (4.30.2)\r\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.20.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.4.0) (0.3.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.4.0) (3.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (4.6.3)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.16.4)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2023.6.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (0.13.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.4.0) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2023.6.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.4.0) (2023.5.7)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.4.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/bitsandbytes/bitsandbytes-0.41.1-py3-none-any.whl\n",
    "!pip install /kaggle/input/peft-whl/peft-0.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69642f6d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-14T01:10:47.872891Z",
     "iopub.status.busy": "2023-09-14T01:10:47.872538Z",
     "iopub.status.idle": "2023-09-14T01:11:02.883832Z",
     "shell.execute_reply": "2023-09-14T01:11:02.882838Z"
    },
    "papermill": {
     "duration": 15.024199,
     "end_time": "2023-09-14T01:11:02.886278",
     "exception": false,
     "start_time": "2023-09-14T01:10:47.862079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from tqdm import tqdm, trange\n",
    "import bitsandbytes\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "import os\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd06b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:02.905775Z",
     "iopub.status.busy": "2023-09-14T01:11:02.904959Z",
     "iopub.status.idle": "2023-09-14T01:11:02.913620Z",
     "shell.execute_reply": "2023-09-14T01:11:02.912752Z"
    },
    "papermill": {
     "duration": 0.020508,
     "end_time": "2023-09-14T01:11:02.915760",
     "exception": false,
     "start_time": "2023-09-14T01:11:02.895252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c41de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:02.936830Z",
     "iopub.status.busy": "2023-09-14T01:11:02.936180Z",
     "iopub.status.idle": "2023-09-14T01:11:02.941463Z",
     "shell.execute_reply": "2023-09-14T01:11:02.940606Z"
    },
    "papermill": {
     "duration": 0.017336,
     "end_time": "2023-09-14T01:11:02.943777",
     "exception": false,
     "start_time": "2023-09-14T01:11:02.926441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b575e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:02.962913Z",
     "iopub.status.busy": "2023-09-14T01:11:02.962166Z",
     "iopub.status.idle": "2023-09-14T01:11:02.967688Z",
     "shell.execute_reply": "2023-09-14T01:11:02.966772Z"
    },
    "papermill": {
     "duration": 0.017164,
     "end_time": "2023-09-14T01:11:02.969771",
     "exception": false,
     "start_time": "2023-09-14T01:11:02.952607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    select = 'large'\n",
    "    model_name = f'/kaggle/input/deberta-v3-{select}-hf-weights'\n",
    "    only_model_name = f'deberta-v3-{select}'\n",
    "    accum_iter = 4\n",
    "    fold = 4\n",
    "    seed = 42\n",
    "    batch_size = 8\n",
    "    max_len = 512\n",
    "    num_epoch = 5\n",
    "    hidden_dropout_prob=0.005\n",
    "    attention_probs_dropout_prob=0.005\n",
    "    lr = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e775f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:02.989066Z",
     "iopub.status.busy": "2023-09-14T01:11:02.988115Z",
     "iopub.status.idle": "2023-09-14T01:11:03.128631Z",
     "shell.execute_reply": "2023-09-14T01:11:03.127536Z"
    },
    "papermill": {
     "duration": 0.152725,
     "end_time": "2023-09-14T01:11:03.131122",
     "exception": false,
     "start_time": "2023-09-14T01:11:02.978397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "prompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n",
    "summary_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "summary_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "\n",
    "train = summary_train.merge(prompts_train, how='left',on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036bf575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:03.150731Z",
     "iopub.status.busy": "2023-09-14T01:11:03.149885Z",
     "iopub.status.idle": "2023-09-14T01:11:03.162104Z",
     "shell.execute_reply": "2023-09-14T01:11:03.161258Z"
    },
    "papermill": {
     "duration": 0.023739,
     "end_time": "2023-09-14T01:11:03.164078",
     "exception": false,
     "start_time": "2023-09-14T01:11:03.140339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_dict = {id : index for index,id in enumerate(train['prompt_id'].unique())}\n",
    "train['fold'] = -1\n",
    "train['fold'] = train['prompt_id'].apply(lambda x : prompt_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1980c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:03.182812Z",
     "iopub.status.busy": "2023-09-14T01:11:03.182508Z",
     "iopub.status.idle": "2023-09-14T01:11:04.452652Z",
     "shell.execute_reply": "2023-09-14T01:11:04.451451Z"
    },
    "papermill": {
     "duration": 1.282464,
     "end_time": "2023-09-14T01:11:04.455152",
     "exception": false,
     "start_time": "2023-09-14T01:11:03.172688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "cfg.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01155e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.476019Z",
     "iopub.status.busy": "2023-09-14T01:11:04.474245Z",
     "iopub.status.idle": "2023-09-14T01:11:04.486627Z",
     "shell.execute_reply": "2023-09-14T01:11:04.485653Z"
    },
    "papermill": {
     "duration": 0.024726,
     "end_time": "2023-09-14T01:11:04.488868",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.464142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = cfg.tokenizer\n",
    "        self.max_len = cfg.max_len\n",
    "        self.fp = df['prompt_text'].values\n",
    "        self.pq = df['prompt_question'].values\n",
    "        self.title = df['prompt_title'].values\n",
    "        self.text = df['text'].values\n",
    "        self.targets = df[['content','wording']].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        pq   =   self.pq[index]\n",
    "        title = self.title[index]\n",
    "        text =   self.text[index]\n",
    "        fp = self.fp[index]\n",
    "        full_text = 'System Message: You are an AI assistant that scores summarized text based on provided questions and text summaries.'+ self.tokenizer.sep_token + pq + self.tokenizer.sep_token + text\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        full_text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        target = self.targets[index]\n",
    "        \n",
    "   \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            \n",
    "        } , torch.tensor(target, dtype=torch.float)\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4698ca99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.507745Z",
     "iopub.status.busy": "2023-09-14T01:11:04.507361Z",
     "iopub.status.idle": "2023-09-14T01:11:04.513755Z",
     "shell.execute_reply": "2023-09-14T01:11:04.512779Z"
    },
    "papermill": {
     "duration": 0.018565,
     "end_time": "2023-09-14T01:11:04.515969",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.497404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_fold(df, n_fold):\n",
    "    dftrain = df[df['fold']!= n_fold]\n",
    "    dfvalid = df[df['fold']== n_fold]\n",
    "    \n",
    "    train_dataset = CustomDataset(dftrain)\n",
    "    valid_dataset = CustomDataset(dfvalid)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset , batch_size=cfg.batch_size, num_workers=0, shuffle=True, pin_memory=True) \n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset , batch_size=cfg.batch_size, num_workers=0, shuffle=False, pin_memory=True) \n",
    "    \n",
    "    return train_loader , valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1beead5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.534923Z",
     "iopub.status.busy": "2023-09-14T01:11:04.534642Z",
     "iopub.status.idle": "2023-09-14T01:11:04.544936Z",
     "shell.execute_reply": "2023-09-14T01:11:04.543929Z"
    },
    "papermill": {
     "duration": 0.022248,
     "end_time": "2023-09-14T01:11:04.547117",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.524869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_with_MP(cfg, n_fold, model, optimizer, train_loader, val_loader, scheduler):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    i = 0\n",
    "    best_loss = 1\n",
    "    gc.collect()\n",
    "    for epoch in range(1, cfg.num_epoch + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for batch, labels in tqdm(iter(train_loader)):\n",
    "            batch = {i: v.to(\"cuda\") for i, v in batch.items()}\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(**batch, labels = labels)\n",
    "                loss = output.loss / cfg.accum_iter\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            i += 1\n",
    "            if i % cfg.accum_iter == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            train_loss.append(loss.detach().cpu())\n",
    "        \n",
    "        _val_loss, scores = validation(model, val_loader)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        scheduler.step()\n",
    "        print(\n",
    "            f\"Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val mcrmse : [{scores['mcrmse']:.5f}]\"\n",
    "        )\n",
    "        \n",
    "        if best_loss >= _val_loss:\n",
    "            model.save_pretrained(f\"/kaggle/working/deberta-v3-base-Fold_{n_fold}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7acd5330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.566737Z",
     "iopub.status.busy": "2023-09-14T01:11:04.566417Z",
     "iopub.status.idle": "2023-09-14T01:11:04.575273Z",
     "shell.execute_reply": "2023-09-14T01:11:04.574316Z"
    },
    "papermill": {
     "duration": 0.02099,
     "end_time": "2023-09-14T01:11:04.577355",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.556365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch, labels in tqdm(iter(val_loader)):\n",
    "            batch = {i: v.to(\"cuda\") for i, v in batch.items()}\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            output = model(**batch,labels = labels)\n",
    "            pred = output.logits\n",
    "            loss = output.loss\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            pred_list += pred.detach().cpu().tolist()\n",
    "            label_list += labels.detach().cpu().tolist()\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        pred_list_re = np.array(pred_list).reshape(-1,2)[:,]\n",
    "        label_list_re = np.array(label_list).reshape(-1,2)[:,]\n",
    "        scores = compute_mcrmse(pred_list_re, label_list_re)\n",
    "\n",
    "    return _val_loss, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221d29aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.596936Z",
     "iopub.status.busy": "2023-09-14T01:11:04.596670Z",
     "iopub.status.idle": "2023-09-14T01:11:04.603726Z",
     "shell.execute_reply": "2023-09-14T01:11:04.602826Z"
    },
    "papermill": {
     "duration": 0.019219,
     "end_time": "2023-09-14T01:11:04.605779",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.586560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(preds, labels):\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6525bb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.625504Z",
     "iopub.status.busy": "2023-09-14T01:11:04.624605Z",
     "iopub.status.idle": "2023-09-14T01:11:04.632275Z",
     "shell.execute_reply": "2023-09-14T01:11:04.628926Z"
    },
    "papermill": {
     "duration": 0.026733,
     "end_time": "2023-09-14T01:11:04.641403",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.614670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "# model_config.update({\n",
    "#         \"hidden_dropout_prob\": cfg.hidden_dropout_prob,\n",
    "#         \"attention_probs_dropout_prob\": cfg.attention_probs_dropout_prob,\n",
    "#         \"num_labels\": 2,\n",
    "#         \"problem_type\": \"regression\"\n",
    "#     })\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name,config = model_config)\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_CLS, r=16, lora_alpha=16, target_modules=['query_proj','value_proj'], lora_dropout=0.1, bias=\"all\", modules_to_save=['classifier','pooler']\n",
    "# )\n",
    "# peft_model = get_peft_model(model,peft_config)\n",
    "\n",
    "# peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ff2645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.681014Z",
     "iopub.status.busy": "2023-09-14T01:11:04.679056Z",
     "iopub.status.idle": "2023-09-14T01:11:04.689160Z",
     "shell.execute_reply": "2023-09-14T01:11:04.685644Z"
    },
    "papermill": {
     "duration": 0.031332,
     "end_time": "2023-09-14T01:11:04.691606",
     "exception": false,
     "start_time": "2023-09-14T01:11:04.660274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peft_model.cuda()\n",
    "# optimizer = torch.optim.AdamW(params = peft_model.parameters(), lr = cfg.lr)\n",
    "# cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10,eta_min = 1e-5)\n",
    "# reduce_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77a64dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T01:11:04.711952Z",
     "iopub.status.busy": "2023-09-14T01:11:04.711055Z",
     "iopub.status.idle": "2023-09-14T01:11:19.729731Z",
     "shell.execute_reply": "2023-09-14T01:11:19.728171Z"
    },
    "papermill": {
     "duration": 15.030859,
     "end_time": "2023-09-14T01:11:19.732175",
     "exception": true,
     "start_time": "2023-09-14T01:11:04.701316",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/peft/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">config.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">117</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config_file = os.path.join(path, CONFIG_NAME)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>117 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>config_file = hf_hub_download(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder, **h   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>kwargs.items(),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Kwargs values</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>):                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">\"repo_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"from_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"to_id\"</span>]:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>110 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>validate_repo_id(arg_value)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> arg_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>has_token = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">158</span> in              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_repo_id</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Repo id must be a string, not {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(repo_id)<span style=\"color: #808000; text-decoration-color: #808000\">}: '{</span>repo_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> repo_id.count(<span style=\"color: #808000; text-decoration-color: #808000\">\"/\"</span>) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>158 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" '{</span>repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}'. Use `repo_type` argument if needed.\"</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">HFValidationError: </span>Repo id must be in the form <span style=\"color: #008000; text-decoration-color: #008000\">'repo_name'</span> or <span style=\"color: #008000; text-decoration-color: #008000\">'namespace/repo_name'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/working/deberta-v3-base-Fold_0.pth'</span>. Use `repo_type` argument if needed.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">7</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"problem_type\"</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"regression\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>})                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name,config = model    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 7 lora_config = LoraConfig.from_pretrained(<span style=\"color: #808000; text-decoration-color: #808000\">f'/kaggle/working/deberta-v3-base-Fold_0.pth'</span>)     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>peft_model = PeftModel.from_pretrained(model,<span style=\"color: #808000; text-decoration-color: #808000\">f'/kaggle/working/deberta-v3-base-Fold_0.pt</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>peft_model.print_trainable_parameters()                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>pref_model = peft_model.merge_and_unload()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/peft/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">config.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">121</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>pretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder, **h   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>121 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't find '{</span>CONFIG_NAME<span style=\"color: #808000; text-decoration-color: #808000\">}' at '{</span>pretrained_model_name   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loaded_attributes = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.from_json_file(config_file)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Can't find <span style=\"color: #008000; text-decoration-color: #008000\">'adapter_config.json'</span> at <span style=\"color: #008000; text-decoration-color: #008000\">'/kaggle/working/deberta-v3-base-Fold_0.pth'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/peft/utils/\u001b[0m\u001b[1;33mconfig.py\u001b[0m:\u001b[94m117\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig_file = os.path.join(path, CONFIG_NAME)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m117 \u001b[2m│   │   │   │   \u001b[0mconfig_file = hf_hub_download(                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder, **h   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m110\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m110 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m158\u001b[0m in              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mvalidate_repo_id\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be a string, not \u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(repo_id)\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m repo_id.count(\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m\"\u001b[0m) > \u001b[94m1\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be in the form \u001b[0m\u001b[33m'\u001b[0m\u001b[33mrepo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m or \u001b[0m\u001b[33m'\u001b[0m\u001b[33mnamespace/repo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. Use `repo_type` argument if needed.\u001b[0m\u001b[33m\"\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mHFValidationError: \u001b[0mRepo id must be in the form \u001b[32m'repo_name'\u001b[0m or \u001b[32m'namespace/repo_name'\u001b[0m: \n",
       "\u001b[32m'/kaggle/working/deberta-v3-base-Fold_0.pth'\u001b[0m. Use `repo_type` argument if needed.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m7\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mproblem_type\u001b[0m\u001b[33m\"\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33mregression\u001b[0m\u001b[33m\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m})                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0mmodel = AutoModelForSequenceClassification.from_pretrained(cfg.model_name,config = model    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 7 lora_config = LoraConfig.from_pretrained(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m/kaggle/working/deberta-v3-base-Fold_0.pth\u001b[0m\u001b[33m'\u001b[0m)     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0mpeft_model = PeftModel.from_pretrained(model,\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33m/kaggle/working/deberta-v3-base-Fold_0.pt\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mpeft_model.print_trainable_parameters()                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0mpref_model = peft_model.merge_and_unload()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/peft/utils/\u001b[0m\u001b[1;33mconfig.py\u001b[0m:\u001b[94m121\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path, CONFIG_NAME, subfolder=subfolder, **h   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m121 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt find \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mCONFIG_NAME\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m at \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0mloaded_attributes = \u001b[96mcls\u001b[0m.from_json_file(config_file)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mCan't find \u001b[32m'adapter_config.json'\u001b[0m at \u001b[32m'/kaggle/working/deberta-v3-base-Fold_0.pth'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "model_config.update({\n",
    "        \"num_labels\": 2,\n",
    "        \"problem_type\": \"regression\"\n",
    "    })\n",
    "model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name,config = model_config)\n",
    "lora_config = LoraConfig.from_pretrained(f'/kaggle/working/deberta-v3-base-Fold_0.pth')\n",
    "peft_model = PeftModel.from_pretrained(model,f'/kaggle/working/deberta-v3-base-Fold_0.pth')\n",
    "peft_model.print_trainable_parameters()\n",
    "pref_model = peft_model.merge_and_unload()\n",
    "peft_model = peft_model.to('cuda')\n",
    "train_loader , valid_loader = prepare_fold(train, 0)\n",
    "_val_loss, scores = validation(peft_model, valid_loader)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T05:37:35.465106Z",
     "iopub.status.busy": "2023-09-12T05:37:35.464673Z",
     "iopub.status.idle": "2023-09-12T07:19:52.172231Z",
     "shell.execute_reply": "2023-09-12T07:19:52.171226Z",
     "shell.execute_reply.started": "2023-09-12T05:37:35.465070Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_fold = 0\n",
    "train_loader, valid_loader = prepare_fold(train, n_fold)\n",
    "\n",
    "# print(len(train_loader))\n",
    "# train_with_MP(cfg, n_fold, peft_model, optimizer, train_loader, valid_loader, cosine_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb490311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T07:19:52.175691Z",
     "iopub.status.busy": "2023-09-12T07:19:52.174975Z",
     "iopub.status.idle": "2023-09-12T07:19:52.182119Z",
     "shell.execute_reply": "2023-09-12T07:19:52.181212Z",
     "shell.execute_reply.started": "2023-09-12T07:19:52.175654Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "# model_config.update({\n",
    "#         \"hidden_dropout_prob\": cfg.hidden_dropout_prob,\n",
    "#         \"attention_probs_dropout_prob\": cfg.attention_probs_dropout_prob,\n",
    "#         \"num_labels\": 2,\n",
    "#         \"problem_type\": \"regression\"\n",
    "#     })\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name,config = model_config)\n",
    "# lora_config = LoraConfig.from_pretrained('/kaggle/working/deberta-v3-base-Fold_0.pth')\n",
    "# peft_model = PeftModel.from_pretrained(model,'/kaggle/working/deberta-v3-base-Fold_0.pth')\n",
    "# peft_model.print_trainable_parameters()\n",
    "# pref_model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c43410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-12T07:19:52.183986Z",
     "iopub.status.busy": "2023-09-12T07:19:52.183524Z",
     "iopub.status.idle": "2023-09-12T07:19:52.191860Z",
     "shell.execute_reply": "2023-09-12T07:19:52.190678Z",
     "shell.execute_reply.started": "2023-09-12T07:19:52.183952Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# peft_model = peft_model.to('cuda')\n",
    "# train_loader, valid_loader = prepare_fold(train, 0)\n",
    "# _val_loss, scores =validation(peft_model,valid_loader)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f9516",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 74.831498,
   "end_time": "2023-09-14T01:11:22.775327",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-14T01:10:07.943829",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
