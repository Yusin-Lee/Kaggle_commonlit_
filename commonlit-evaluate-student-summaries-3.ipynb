{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b4e44a",
   "metadata": {
    "_cell_guid": "02f98fc4-02b5-4c1d-9bb2-19999d54d913",
    "_uuid": "7a454ac4-4a18-45e8-b6d0-65689fe5a907",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:35.759368Z",
     "iopub.status.busy": "2023-08-18T01:33:35.758431Z",
     "iopub.status.idle": "2023-08-18T01:33:51.918456Z",
     "shell.execute_reply": "2023-08-18T01:33:51.917143Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 16.171982,
     "end_time": "2023-08-18T01:33:51.921526",
     "exception": false,
     "start_time": "2023-08-18T01:33:35.749544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "#torch.multiprocessing.set_start_method('spawn')\n",
    "torch.backends.cudnn.benchmark=False\n",
    "torch.backends.cudnn.deterministic=True\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1a9b0a",
   "metadata": {
    "_cell_guid": "9a6607ab-3e10-4e01-922a-ae54f7ea9905",
    "_uuid": "02bbdf11-e6db-4051-8171-c74c9d4d9882",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:51.937673Z",
     "iopub.status.busy": "2023-08-18T01:33:51.937342Z",
     "iopub.status.idle": "2023-08-18T01:33:51.941863Z",
     "shell.execute_reply": "2023-08-18T01:33:51.940907Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01518,
     "end_time": "2023-08-18T01:33:51.944327",
     "exception": false,
     "start_time": "2023-08-18T01:33:51.929147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af69af",
   "metadata": {
    "_cell_guid": "3845c492-31f3-4fb7-a6d3-8faca30f1383",
    "_uuid": "a0f1d949-283b-49ce-8c21-97584934f237",
    "papermill": {
     "duration": 0.007241,
     "end_time": "2023-08-18T01:33:51.958649",
     "exception": false,
     "start_time": "2023-08-18T01:33:51.951408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG and Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efc5fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:51.973484Z",
     "iopub.status.busy": "2023-08-18T01:33:51.973187Z",
     "iopub.status.idle": "2023-08-18T01:33:51.983672Z",
     "shell.execute_reply": "2023-08-18T01:33:51.982779Z"
    },
    "papermill": {
     "duration": 0.020268,
     "end_time": "2023-08-18T01:33:51.985785",
     "exception": false,
     "start_time": "2023-08-18T01:33:51.965517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb80bf68",
   "metadata": {
    "_cell_guid": "908ea877-2455-4683-a5fe-ea8d560eb284",
    "_uuid": "cc26de78-1dfd-4955-ba7b-0648542ad10d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:52.000560Z",
     "iopub.status.busy": "2023-08-18T01:33:52.000299Z",
     "iopub.status.idle": "2023-08-18T01:33:52.010079Z",
     "shell.execute_reply": "2023-08-18T01:33:52.009049Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019453,
     "end_time": "2023-08-18T01:33:52.012123",
     "exception": false,
     "start_time": "2023-08-18T01:33:51.992670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    select = 'base'\n",
    "    model_name = f'/kaggle/input/deberta-v3-{select}/deberta-v3-{select}'\n",
    "    only_model_name = f'deberta-v3-{select}'\n",
    "    accum_iter = 8\n",
    "    fold = 4\n",
    "    split = 5\n",
    "    seed = 42\n",
    "    batch_size = 4\n",
    "    max_len = 1024\n",
    "    num_epoch = 4\n",
    "    T_max= 1334\n",
    "    hidden_dropout_prob=0.005\n",
    "    attention_probs_dropout_prob=0.005\n",
    "\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    weight_decay =  1e-6\n",
    "    min_lr = 1e-6\n",
    "    freezing = False\n",
    "    pooling = 'GemText'\n",
    "    weight_decay = 1e-2\n",
    "    encoder_lr = 1e-5\n",
    "    decoder_lr = 1e-5\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    \n",
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]#.detach().to('cpu').numpy()\n",
    "        y_pred = y_preds[:,i]#.detach().to('cpu').numpy()\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def score_loss(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return {\n",
    "        'mcrmse_score' : mcrmse_score,\n",
    "        'Content_score' : scores[0],\n",
    "        'Wording_score' : scores[1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7839538",
   "metadata": {
    "_cell_guid": "c9a87ff7-d29f-403c-8067-0053e9afa572",
    "_uuid": "ccd98448-cb3f-41e4-8417-95649e1783f0",
    "papermill": {
     "duration": 0.007074,
     "end_time": "2023-08-18T01:33:52.026291",
     "exception": false,
     "start_time": "2023-08-18T01:33:52.019217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b60794",
   "metadata": {
    "_cell_guid": "208f90f7-4192-48d0-8d81-ebf7c35c7893",
    "_uuid": "38c786b1-5968-4872-845f-c3cd96d8a0cf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:52.041471Z",
     "iopub.status.busy": "2023-08-18T01:33:52.041185Z",
     "iopub.status.idle": "2023-08-18T01:33:52.176286Z",
     "shell.execute_reply": "2023-08-18T01:33:52.175291Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.145477,
     "end_time": "2023-08-18T01:33:52.178700",
     "exception": false,
     "start_time": "2023-08-18T01:33:52.033223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n",
    "prompts_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\n",
    "summary_train = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n",
    "summary_test = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n",
    "\n",
    "train = prompts_train.merge(summary_train, on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239bc88f",
   "metadata": {
    "_cell_guid": "a3e2ef9a-7236-47be-b036-a1aecb62bf16",
    "_uuid": "39a96242-b2e9-4fa2-a082-f98075ee4a8f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:52.194827Z",
     "iopub.status.busy": "2023-08-18T01:33:52.194535Z",
     "iopub.status.idle": "2023-08-18T01:33:52.215630Z",
     "shell.execute_reply": "2023-08-18T01:33:52.214701Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.031581,
     "end_time": "2023-08-18T01:33:52.217995",
     "exception": false,
     "start_time": "2023-08-18T01:33:52.186414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['fold'] = -1\n",
    "fold = StratifiedKFold(n_splits=cfg.fold, shuffle=True, random_state=cfg.seed)\n",
    "for n, (train_index, val_index) in enumerate(fold.split(train, train['prompt_id'])):\n",
    "    train.loc[val_index, 'fold'] = n\n",
    "train['fold'] = train['fold'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbd6af",
   "metadata": {
    "_cell_guid": "8f0094eb-20e4-4dd0-b35b-da4c4a37c6fd",
    "_uuid": "94aec617-4a06-474f-ae03-f29b6d7c4141",
    "papermill": {
     "duration": 0.006898,
     "end_time": "2023-08-18T01:33:52.232515",
     "exception": false,
     "start_time": "2023-08-18T01:33:52.225617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fc47aa",
   "metadata": {
    "_cell_guid": "bed8995a-722d-4cf5-9951-996d7713d14b",
    "_uuid": "87e08215-12fb-4ef9-a119-b0a2be0110e5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:52.247136Z",
     "iopub.status.busy": "2023-08-18T01:33:52.246834Z",
     "iopub.status.idle": "2023-08-18T01:33:53.831588Z",
     "shell.execute_reply": "2023-08-18T01:33:53.830423Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.594897,
     "end_time": "2023-08-18T01:33:53.834157",
     "exception": false,
     "start_time": "2023-08-18T01:33:52.239260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "cfg.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6608c32",
   "metadata": {
    "_cell_guid": "ea08ac4f-a9ea-47bf-9a74-9813ba368652",
    "_uuid": "912042e2-f163-4e4a-b713-7a24b02c3bed",
    "papermill": {
     "duration": 0.007321,
     "end_time": "2023-08-18T01:33:53.849375",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.842054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e07c26",
   "metadata": {
    "_cell_guid": "30d48751-b9d0-428c-bfde-b058b8f31203",
    "_uuid": "6be6e995-962c-40e9-830f-fb820d7c2650",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:53.866071Z",
     "iopub.status.busy": "2023-08-18T01:33:53.865344Z",
     "iopub.status.idle": "2023-08-18T01:33:53.883272Z",
     "shell.execute_reply": "2023-08-18T01:33:53.882342Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029031,
     "end_time": "2023-08-18T01:33:53.885514",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.856483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = cfg.tokenizer\n",
    "        self.max_len = cfg.max_len\n",
    "        self.fp = df['prompt_text'].values\n",
    "        self.pq = df['prompt_question'].values\n",
    "        self.title = df['prompt_title'].values\n",
    "        self.text = df['text'].values\n",
    "        self.targets = df['content'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        pq   =   self.pq[index]\n",
    "        title = self.title[index]\n",
    "        text =   self.text[index]\n",
    "        fp = self.fp[index]\n",
    "        full_text = title + self.tokenizer.sep_token + pq + self.tokenizer.sep_token + text\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        full_text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        target = self.targets[index]\n",
    "        \n",
    "   \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            \n",
    "        } , torch.tensor(target, dtype=torch.float)\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs\n",
    "\n",
    "class WordingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = cfg.tokenizer\n",
    "        self.max_len = cfg.max_len\n",
    "        self.fp = df['prompt_text'].values\n",
    "        self.pq = df['prompt_question'].values\n",
    "        self.title = df['prompt_title'].values\n",
    "        self.text = df['text'].values\n",
    "        self.targets = df['wording'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        pq   =   self.pq[index]\n",
    "        title = self.title[index]\n",
    "        text =   self.text[index]\n",
    "        fp = self.fp[index]\n",
    "        full_text = title + self.tokenizer.sep_token + pq + self.tokenizer.sep_token + text\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "                        full_text,\n",
    "                        truncation=True,\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=self.max_len,\n",
    "                        padding='max_length'\n",
    "                    )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        target = self.targets[index]\n",
    "        \n",
    "   \n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            \n",
    "        } , torch.tensor(target, dtype=torch.float)\n",
    "\n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:, :mask_len]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8599412",
   "metadata": {
    "_cell_guid": "f9d38f10-aecd-478d-b2e2-45d277eeff0f",
    "_uuid": "31a9603a-7e39-4fc7-8953-aa5e646b4d3d",
    "papermill": {
     "duration": 0.007377,
     "end_time": "2023-08-18T01:33:53.900086",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.892709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b126d3e7",
   "metadata": {
    "_cell_guid": "e5761d58-5dcf-44c6-b348-5b255e4d1d1d",
    "_uuid": "09d61ff8-b2fd-4e6f-a66b-2bed0218aff5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:53.915788Z",
     "iopub.status.busy": "2023-08-18T01:33:53.915524Z",
     "iopub.status.idle": "2023-08-18T01:33:53.923363Z",
     "shell.execute_reply": "2023-08-18T01:33:53.922342Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018202,
     "end_time": "2023-08-18T01:33:53.925657",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.907455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_run(model, criterion, optimizer, dataloader, accelerator): # \n",
    "    gc.collect()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    dataset_size = 0.0 \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (data , labels) in bar:\n",
    "        inputs , targets = collate(data) , labels\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "        loss = criterion(outputs.logits, targets)\n",
    "        loss = loss/cfg.accum_iter\n",
    "        accelerator.backward(loss)\n",
    "        if ((batch_idx + 1) % cfg.accum_iter == 0) or (batch_idx + 1 == len(dataloader)):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "    epoch_loss = running_loss/dataset_size\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8da17e",
   "metadata": {
    "_cell_guid": "d7596102-b489-4208-83ab-e2c4de09345c",
    "_uuid": "0bf2c4a0-ad88-4b21-bd44-ae123f88310c",
    "papermill": {
     "duration": 0.007246,
     "end_time": "2023-08-18T01:33:53.939953",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.932707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Validtaion Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf0338b",
   "metadata": {
    "_cell_guid": "3877e5d0-3a72-4042-8b08-20de49b4ea9e",
    "_uuid": "16a5cb6c-f375-4c92-9ae9-4a3c7436fa01",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:53.957197Z",
     "iopub.status.busy": "2023-08-18T01:33:53.956881Z",
     "iopub.status.idle": "2023-08-18T01:33:53.966158Z",
     "shell.execute_reply": "2023-08-18T01:33:53.965044Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020289,
     "end_time": "2023-08-18T01:33:53.968333",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.948044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_run(model , criterion, dataloader, accelerator):\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    dataset_size = 0.0\n",
    "    \n",
    "    predictions = []\n",
    "    y_labels = []\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for batch_idx, (data , labels) in bar:\n",
    "        inputs , targets = collate(data) , labels\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        outputs, targets = accelerator.gather_for_metrics((outputs, targets))\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        predictions.append(outputs.detach().to('cpu').numpy())\n",
    "        y_labels.append(labels.detach().to('cpu').numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    y_labels    = np.concatenate(y_labels)\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    \n",
    "    return epoch_loss , predictions , y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e74b046",
   "metadata": {
    "_cell_guid": "a6f32f61-796b-4b45-80c1-16b716cba188",
    "_uuid": "3fe494ca-076f-4d54-b906-f32254c9f57e",
    "papermill": {
     "duration": 0.006947,
     "end_time": "2023-08-18T01:33:53.982792",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.975845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0db0709",
   "metadata": {
    "_cell_guid": "f36c5865-8c50-4ff4-af1b-8c4a14556e1e",
    "_uuid": "26762756-82e2-472a-9af8-5cdb8839aeba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:53.999040Z",
     "iopub.status.busy": "2023-08-18T01:33:53.998759Z",
     "iopub.status.idle": "2023-08-18T01:33:54.011450Z",
     "shell.execute_reply": "2023-08-18T01:33:54.010619Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023328,
     "end_time": "2023-08-18T01:33:54.013423",
     "exception": false,
     "start_time": "2023-08-18T01:33:53.990095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_fold(n_fold):\n",
    "    dftrain = train[train['fold']!= n_fold]\n",
    "    dfvalid = train[train['fold']== n_fold]\n",
    "    \n",
    "    train_dataset_content = ContentDataset(dftrain)\n",
    "    valid_dataset_content = ContentDataset(dfvalid)\n",
    "    \n",
    "    train_content_loader = torch.utils.data.DataLoader(train_dataset_content , batch_size=cfg.batch_size, num_workers=2, shuffle=True, pin_memory=True) \n",
    "    valid_content_loader = torch.utils.data.DataLoader(valid_dataset_content , batch_size=cfg.batch_size, num_workers=2, shuffle=False, pin_memory=True) \n",
    "    \n",
    "    train_dataset_Wording = WordingDataset(dftrain)\n",
    "    valid_dataset_Wording = WordingDataset(dfvalid)\n",
    "    \n",
    "    train_Wording_loader = torch.utils.data.DataLoader(train_dataset_Wording , batch_size=cfg.batch_size, num_workers=2, shuffle=True, pin_memory=True) # \n",
    "    valid_Wording_loader = torch.utils.data.DataLoader(valid_dataset_Wording , batch_size=cfg.batch_size, num_workers=2, shuffle=False, pin_memory=True) # \n",
    "\n",
    "    \n",
    "    return train_content_loader , valid_content_loader, train_Wording_loader, valid_Wording_loader\n",
    "\n",
    "def oof_df(n_fold , true , pred):\n",
    "    df_pred = pd.DataFrame(pred ,columns= ['pred_content' , 'pred_wording'])\n",
    "    df_real = pd.DataFrame(true ,columns= ['content' , 'wording'])\n",
    "    \n",
    "    df = pd.concat([df_real , df_pred],1)\n",
    "    return df\n",
    "\n",
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "              'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "              'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "              'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb079a",
   "metadata": {
    "_cell_guid": "94b3e0f9-8680-4c2b-a2a2-f1021ef2ac06",
    "_uuid": "9006d7de-6c11-4551-8440-76aece0ee4bd",
    "papermill": {
     "duration": 0.007256,
     "end_time": "2023-08-18T01:33:54.027924",
     "exception": false,
     "start_time": "2023-08-18T01:33:54.020668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38e7973",
   "metadata": {
    "_cell_guid": "19410bd9-0ca3-453b-8316-813f29174606",
    "_uuid": "24e139ef-cc04-4abf-927f-8715985c32f9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:54.043837Z",
     "iopub.status.busy": "2023-08-18T01:33:54.043085Z",
     "iopub.status.idle": "2023-08-18T01:33:54.049854Z",
     "shell.execute_reply": "2023-08-18T01:33:54.048909Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016881,
     "end_time": "2023-08-18T01:33:54.052013",
     "exception": false,
     "start_time": "2023-08-18T01:33:54.035132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MCRMSE(y_trues, y_preds):\n",
    "    scores = []\n",
    "    idxes = y_trues.shape[1]\n",
    "    for i in range(idxes):\n",
    "        y_true = y_trues[:,i]#.detach().to('cpu').numpy()\n",
    "        y_pred = y_preds[:,i]#.detach().to('cpu').numpy()\n",
    "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
    "        scores.append(score)\n",
    "    mcrmse_score = np.mean(scores)\n",
    "    return mcrmse_score, scores\n",
    "\n",
    "def score_loss(y_trues, y_preds):\n",
    "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
    "    return {\n",
    "        'mcrmse_score' : mcrmse_score,\n",
    "        'Content_score' : scores[0],\n",
    "        'Wording_score' : scores[1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a4cce8",
   "metadata": {
    "_cell_guid": "4fdeaf8a-77a1-4dc3-b7cb-2e26631dd55c",
    "_uuid": "62b16667-d73e-4159-8619-8b951b1f4f38",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:54.067665Z",
     "iopub.status.busy": "2023-08-18T01:33:54.067387Z",
     "iopub.status.idle": "2023-08-18T01:33:54.078238Z",
     "shell.execute_reply": "2023-08-18T01:33:54.077380Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020927,
     "end_time": "2023-08-18T01:33:54.080262",
     "exception": false,
     "start_time": "2023-08-18T01:33:54.059335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def content_loop(mixed_precision='fp16', seed=42, n_fold=0):\n",
    "    \n",
    "\n",
    "    accelerator = Accelerator(gradient_accumulation_steps=cfg.accum_iter)# , mixed_precision=mixed_precision\n",
    "    train_content_loader , valid_content_loader, train_Wording_loader, valid_Wording_loader = prepare_fold(fold=n_fold)\n",
    "\n",
    "\n",
    "    model_config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "    model_config.update({\n",
    "            \"hidden_dropout_prob\": cfg.hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": cfg.attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\"\n",
    "        })\n",
    "\n",
    "    \n",
    "    with accelerator.main_process_first():\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(cfg.model_name, config=model_config)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.encoder_lr, eps=cfg.eps, betas=cfg.betas)\n",
    "    \n",
    "    model, optimizer, train_loader, valid_loader = accelerator.prepare(model, optimizer, train_content_loader, valid_content_loader)\n",
    "    criterion = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "    best_epoch_score = np.inf\n",
    "\n",
    "    for epoch in range(cfg.num_epoch):\n",
    "\n",
    "        train_loss  = train_run(model, criterion, optimizer, train_content_loader, accelerator)#, scheduler\n",
    "        valid_loss , valid_preds , valid_labels  = valid_run(model , criterion, valid_content_loader, accelerator)\n",
    "\n",
    "        print(f'train_loss : {train_loss}, valid_loss : {valid_loss}, {score}')\n",
    "        if valid_loss < best_epoch_score:\n",
    "            best_epoch_score = valid_loss\n",
    "            accelerator.wait_for_everyone()\n",
    "            model_for_save = accelerator.unwrap_model(model)\n",
    "            torch.save(model_for_save.state_dict(),f'/kaggle/working/deberta-v3-base-Fold_{n_fold}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af901ed",
   "metadata": {
    "_cell_guid": "cb1ce332-f37a-41da-849d-3b1e97137106",
    "_uuid": "3f7811be-e5de-4ecc-b910-2b6dcba4a48e",
    "execution": {
     "iopub.execute_input": "2023-08-18T01:33:54.098438Z",
     "iopub.status.busy": "2023-08-18T01:33:54.098161Z",
     "iopub.status.idle": "2023-08-18T01:33:54.914883Z",
     "shell.execute_reply": "2023-08-18T01:33:54.913560Z"
    },
    "papermill": {
     "duration": 0.827994,
     "end_time": "2023-08-18T01:33:54.917872",
     "exception": false,
     "start_time": "2023-08-18T01:33:54.089878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Launching training on 2 GPUs.\n",
      "1\n",
      "Launching training on 2 GPUs.\n",
      "2\n",
      "Launching training on 2 GPUs.\n",
      "3\n",
      "Launching training on 2 GPUs.\n"
     ]
    }
   ],
   "source": [
    "for n_fold in range(4):\n",
    "    print(n_fold)\n",
    "    notebook_launcher(content_loop,('fp16',42,n_fold), num_processes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0de4db",
   "metadata": {
    "_cell_guid": "e953b007-cbbb-4753-a729-33937388dc92",
    "_uuid": "2eb8958d-4046-4315-9452-321a6190c907",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007451,
     "end_time": "2023-08-18T01:33:54.933347",
     "exception": false,
     "start_time": "2023-08-18T01:33:54.925896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.938802,
   "end_time": "2023-08-18T01:33:57.961134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-18T01:33:25.022332",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
